<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.
<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.
[2025-05-21 17:39:20,255 systems.py:174 WARNING] nvidia-smi command exists but failed to execute - Ignoring NUMA detection.
[2025-05-21 17:39:20,531 main.py:232 INFO] Detected system ID: KnownSystem.Orin
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/work/code/main.py", line 234, in <module>
    main(main_args, DETECTED_SYSTEM)
  File "/work/code/main.py", line 144, in main
    dispatch_action(main_args, config_dict, workload_setting)
  File "/work/code/main.py", line 204, in dispatch_action
    handler.run()
  File "/work/code/actionhandler/base.py", line 75, in run
    self.setup()
  File "/work/code/actionhandler/run_harness.py", line 82, in setup
    duper.run()
  File "/work/code/common/protected_super.py", line 137, in _f
    return r(*args, **kwargs)
  File "/work/code/actionhandler/base.py", line 75, in run
    self.setup()
  File "/work/code/actionhandler/generate_conf_files.py", line 70, in setup
    self.harness, self.benchmark_conf = get_harness(self.benchmark_conf, None)
  File "/work/code/__init__.py", line 208, in get_harness
    harness = get_cls(G_HARNESS_CLASS_MAP[k])(conf, benchmark)
  File "/work/code/bert/tensorrt/harness.py", line 28, in __init__
    super(BertHarness, self).__init__(args, benchmark)
  File "/work/code/common/harness.py", line 92, in __init__
    self.enumerate_engines()
  File "/work/code/common/harness.py", line 183, in enumerate_engines
    gpu_e2e_batch_size = get_e2e_batch_size(self.args["gpu_batch_size"])
  File "/work/code/common/utils.py", line 63, in get_e2e_batch_size
    raise ValueError(f"{batch_size_dict} input batch_size_dict is empty.")
ValueError: {} input batch_size_dict is empty.
